{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-28T22:14:23.226935Z",
     "iopub.status.busy": "2025-08-28T22:14:23.226628Z",
     "iopub.status.idle": "2025-08-28T22:14:23.548007Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/4datathon/sample_submission.csv\n",
      "/kaggle/input/4datathon/prepared_test.csv\n",
      "/kaggle/input/4datathon/prepared_train.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/4datathon/preapared_train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/4datathon/prepared_test.csv')\n",
    "\n",
    "features = ['event_count', 'unique_products', 'unique_categories', \n",
    "            'event_type_ADD_CART', 'event_type_BUY', 'event_type_REMOVE_CART', \n",
    "            'event_type_VIEW', 'duration']\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['session_value']\n",
    "\n",
    "X_test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "train_df = pd.read_csv('/kaggle/input/4datathon/prepared_train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/4datathon/prepared_test.csv')\n",
    "\n",
    "features = ['event_count', 'unique_products', 'unique_categories',\n",
    "            'event_type_ADD_CART', 'event_type_BUY', 'event_type_REMOVE_CART',\n",
    "            'event_type_VIEW','duration']\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['session_value']\n",
    "X_test = test_df[features]\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, objective='reg:squarederror', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "# LightGBM \n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "lgb_predictions = lgb_model.predict(X_test)\n",
    "\n",
    "# CatBoost \n",
    "cat_model = CatBoostRegressor(n_estimators=100, learning_rate=0.1, verbose=0, random_state=42)\n",
    "cat_model.fit(X_train, y_train)\n",
    "cat_predictions = cat_model.predict(X_test)\n",
    "\n",
    "# --- TAHMİNLERİN ORTALAMASI\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'xgb': xgb_predictions,\n",
    "    'lgb': lgb_predictions,\n",
    "    'cat': cat_predictions\n",
    "})\n",
    "\n",
    "final_predictions = predictions_df.mean(axis=1)\n",
    "\n",
    "# --- SUBMISSIONS\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'user_session': test_df['user_session'],\n",
    "    'session_value': final_predictions\n",
    "})\n",
    "\n",
    "submission_df.to_csv('ensembled_tahminler.csv', index=False)\n",
    "\n",
    "print(\"Ensembled tahminler başarıyla 'ensembled_tahminler.csv' dosyasına kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ---- Load ----\n",
    "train_df = pd.read_csv('/kaggle/input/4datathon/prepared_train.csv')\n",
    "test_df  = pd.read_csv('/kaggle/input/4datathon/prepared_test.csv')\n",
    "\n",
    "# ---- Features ----\n",
    "features = ['unique_products', 'unique_categories',\n",
    "            'event_type_ADD_CART', 'event_type_BUY', 'event_type_REMOVE_CART',\n",
    "            'event_type_VIEW', 'duration']\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df['session_value']\n",
    "X_test = test_df[features]\n",
    "\n",
    "# ---- Log-target ----\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# ---- Train/Validation split ----\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---- Model ----\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=5000,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=5,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    objective='reg:squarederror',\n",
    "    tree_method='hist',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ---- Fit with early stopping ----\n",
    "model.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='rmse',\n",
    "    early_stopping_rounds=200,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# ---- Validation RMSE ----\n",
    "val_pred_log = model.predict(X_val)\n",
    "val_pred = np.expm1(val_pred_log)\n",
    "val_rmse = mean_squared_error(np.expm1(y_val), val_pred, squared=False)\n",
    "print(\"Validation RMSE (original scale):\", round(val_rmse, 6))\n",
    "print(\"Best iteration:\", model.best_iteration)\n",
    "\n",
    "# ---- Test predictions ----\n",
    "test_pred = np.expm1(model.predict(X_test))\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'user_session': test_df['user_session'],\n",
    "    'session_value': test_pred\n",
    "})\n",
    "submission_df.to_csv('tahminler.csv', index=False)\n",
    "print(\"Saved tahminler.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "####BEST submission\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "train_df = pd.read_csv('/kaggle/input/4datathon/prepared_train.csv')\n",
    "\n",
    "test_df = pd.read_csv('/kaggle/input/4datathon/prepared_test.csv')\n",
    "\n",
    "features = ['unique_products', 'unique_categories',\n",
    "            'event_type_ADD_CART', 'event_type_BUY', 'event_type_REMOVE_CART',\n",
    "            'event_type_VIEW', 'duration']\n",
    "\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['session_value']\n",
    "\n",
    "X_test = test_df[features]\n",
    "\n",
    "model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, objective='reg:squarederror', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "\n",
    "'user_session': test_df['user_session'],\n",
    "'session_value': predictions})\n",
    "\n",
    "submission_df.to_csv('tahminler.csv', index=False)\n",
    "print(\"Tahminler başarıyla 'tahminler.csv' dosyasına kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "# XGBoost + Optuna Hyperparam Tuning\n",
    "!pip -q install optuna\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ---- Load prepared data ----\n",
    "train = pd.read_csv(\"/kaggle/input/4datathon/prepared_train.csv\")\n",
    "test  = pd.read_csv(\"/kaggle/input/4datathon/prepared_test.csv\")\n",
    "sample = pd.read_csv(\"/kaggle/input/4datathon/sample_submission.csv\")\n",
    "\n",
    "# ---- Feature set ----\n",
    "core_features = [\n",
    "    \"unique_products\",\"unique_categories\",\n",
    "    \"event_type_ADD_CART\",\"event_type_BUY\",\n",
    "    \"event_type_REMOVE_CART\",\"event_type_VIEW\",\n",
    "    \"duration\"\n",
    "]\n",
    "time_features = core_features + [\"hour\",\"day_of_week\",\"day_of_month\"]\n",
    "\n",
    "use_time = all(c in train.columns for c in time_features)\n",
    "features = time_features if use_time else core_features\n",
    "print(\"Using features:\", features)\n",
    "\n",
    "X = train[features]\n",
    "y = train[\"session_value\"].astype(float)\n",
    "X_test = test[features]\n",
    "\n",
    "# ---- KFold ----\n",
    "KFOLDS = 5\n",
    "kf = KFold(n_splits=KFOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# ---- XGBoost fit helper ----\n",
    "def fit_xgb_dmatrix(Xtr, ytr, Xv, yv, params, num_boost_round=5000, early_stopping_rounds=200):\n",
    "    dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "    dvalid = xgb.DMatrix(Xv,  label=yv)\n",
    "    evals = [(dtrain, \"train\"), (dvalid, \"valid\")]\n",
    "    booster = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    return booster\n",
    "\n",
    "def xgb_predict(booster, X_):\n",
    "    d_ = xgb.DMatrix(X_)\n",
    "    ntree_limit = getattr(booster, \"best_ntree_limit\", 0)\n",
    "    return booster.predict(d_, ntree_limit=ntree_limit) if ntree_limit else booster.predict(d_)\n",
    "\n",
    "# ---- Optuna objective ----\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.08, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 10),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1.0, 10.0, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 1e-1, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 1e2, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    rmses = []\n",
    "    # Log-target CV\n",
    "    y_log = np.log1p(y)\n",
    "    for tr_idx, val_idx in kf.split(X, y):\n",
    "        Xtr, Xv = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        ytr, yv = y_log.iloc[tr_idx], y_log.iloc[val_idx]\n",
    "\n",
    "        booster = fit_xgb_dmatrix(\n",
    "            Xtr, ytr, Xv, yv,\n",
    "            params=params,\n",
    "            num_boost_round=5000,\n",
    "            early_stopping_rounds=200\n",
    "        )\n",
    "        p_val = xgb_predict(booster, Xv)\n",
    "        rmse = np.sqrt(mean_squared_error(np.expm1(yv), np.expm1(p_val)))\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    cv_rmse = float(np.mean(rmses))\n",
    "    return cv_rmse\n",
    "\n",
    "# ---- Optuna Tuning ----\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "N_TRIALS = 50 \n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "print(\"Best CV RMSE:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "# ---- En iyi parametrelerle 5-Fold OOF + Test (LOG-TARGET) ----\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"seed\": 42\n",
    "})\n",
    "\n",
    "oof = np.zeros(len(X))\n",
    "test_preds_accum = np.zeros(len(X_test))\n",
    "\n",
    "y_log = np.log1p(y)\n",
    "fold_best_rounds = []\n",
    "\n",
    "for tr_idx, val_idx in kf.split(X, y):\n",
    "    Xtr, Xv = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    ytr, yv = y_log.iloc[tr_idx], y_log.iloc[val_idx]\n",
    "\n",
    "    booster = fit_xgb_dmatrix(\n",
    "        Xtr, ytr, Xv, yv,\n",
    "        params=best_params,\n",
    "        num_boost_round=10000,\n",
    "        early_stopping_rounds=300\n",
    "    )\n",
    "    # Val\n",
    "    p_val = xgb_predict(booster, Xv)\n",
    "    oof[val_idx] = np.expm1(p_val)\n",
    "\n",
    "    # Test\n",
    "    p_test = xgb_predict(booster, X_test)\n",
    "    test_preds_accum += np.expm1(p_test) / KFOLDS\n",
    "\n",
    "    #diagnostic\n",
    "    best_iter = getattr(booster, \"best_iteration\", None)\n",
    "    if best_iter is None:\n",
    "        best_iter = int(getattr(booster, \"best_ntree_limit\", 0) or 0)\n",
    "    fold_best_rounds.append(best_iter)\n",
    "\n",
    "# ---- OOF RMSE ----\n",
    "oof_rmse = np.sqrt(mean_squared_error(y, oof))\n",
    "print(\"OOF RMSE (log-target with best params):\", round(oof_rmse, 6))\n",
    "print(\"Fold best rounds:\", fold_best_rounds)\n",
    "\n",
    "# ---- LOG-TARGET submission ----\n",
    "sub_log = sample.copy()\n",
    "sub_log[\"session_value\"] = test_preds_accum\n",
    "sub_log.to_csv(\"submission_xgb_optuna_log.csv\", index=False)\n",
    "print(\"Saved: submission_xgb_optuna_log.csv\")\n",
    "\n",
    "\n",
    "oof_normal = np.zeros(len(X))\n",
    "test_preds_normal = np.zeros(len(X_test))\n",
    "\n",
    "for tr_idx, val_idx in kf.split(X, y):\n",
    "    Xtr, Xv = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    ytr, yv = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "    booster = fit_xgb_dmatrix(\n",
    "        Xtr, ytr, Xv, yv,\n",
    "        params=best_params,\n",
    "        num_boost_round=10000,\n",
    "        early_stopping_rounds=300\n",
    "    )\n",
    "    p_val = xgb_predict(booster, Xv)\n",
    "    oof_normal[val_idx] = p_val\n",
    "\n",
    "    p_test = xgb_predict(booster, X_test)\n",
    "    test_preds_normal += p_test / KFOLDS\n",
    "\n",
    "oof_rmse_normal = np.sqrt(mean_squared_error(y, oof_normal))\n",
    "print(\"OOF RMSE (normal target, same params):\", round(oof_rmse_normal, 6))\n",
    "\n",
    "sub_normal = sample.copy()\n",
    "sub_normal[\"session_value\"] = test_preds_normal\n",
    "sub_normal.to_csv(\"submission_xgb_optuna_normal.csv\", index=False)\n",
    "print(\"Saved: submission_xgb_optuna_normal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T22:43:13.162330Z",
     "iopub.status.busy": "2025-08-28T22:43:13.161723Z",
     "iopub.status.idle": "2025-08-28T22:52:56.904399Z",
     "shell.execute_reply": "2025-08-28T22:52:56.903747Z",
     "shell.execute_reply.started": "2025-08-28T22:43:13.162300Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[685]\ttraining's rmse: 0.441695\tvalid_1's rmse: 0.450392\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[496]\ttraining's rmse: 0.444282\tvalid_1's rmse: 0.444631\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[681]\ttraining's rmse: 0.441671\tvalid_1's rmse: 0.449839\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[564]\ttraining's rmse: 0.442508\tvalid_1's rmse: 0.449516\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[590]\ttraining's rmse: 0.443155\tvalid_1's rmse: 0.446393\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\ttraining's rmse: 0.440064\tvalid_1's rmse: 0.450364\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\ttraining's rmse: 0.442815\tvalid_1's rmse: 0.444599\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's rmse: 0.440499\tvalid_1's rmse: 0.450101\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttraining's rmse: 0.441877\tvalid_1's rmse: 0.449757\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttraining's rmse: 0.442143\tvalid_1's rmse: 0.446453\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's rmse: 0.436282\tvalid_1's rmse: 0.451292\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's rmse: 0.438791\tvalid_1's rmse: 0.445969\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\ttraining's rmse: 0.437357\tvalid_1's rmse: 0.450653\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's rmse: 0.437363\tvalid_1's rmse: 0.450049\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's rmse: 0.437971\tvalid_1's rmse: 0.446893\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttraining's rmse: 0.439075\tvalid_1's rmse: 0.450687\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[352]\ttraining's rmse: 0.441268\tvalid_1's rmse: 0.445077\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[324]\ttraining's rmse: 0.440438\tvalid_1's rmse: 0.450246\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[321]\ttraining's rmse: 0.440792\tvalid_1's rmse: 0.449658\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[370]\ttraining's rmse: 0.440427\tvalid_1's rmse: 0.446468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1934]\ttraining's rmse: 0.443409\tvalid_1's rmse: 0.450262\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1067]\ttraining's rmse: 0.446524\tvalid_1's rmse: 0.445172\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1450]\ttraining's rmse: 0.444441\tvalid_1's rmse: 0.44989\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2160]\ttraining's rmse: 0.44336\tvalid_1's rmse: 0.449474\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2044]\ttraining's rmse: 0.444229\tvalid_1's rmse: 0.446521\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[472]\ttraining's rmse: 0.441242\tvalid_1's rmse: 0.450579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's rmse: 0.442562\tvalid_1's rmse: 0.444657\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[321]\ttraining's rmse: 0.442903\tvalid_1's rmse: 0.449983\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[436]\ttraining's rmse: 0.441842\tvalid_1's rmse: 0.449547\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[523]\ttraining's rmse: 0.441694\tvalid_1's rmse: 0.446577\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.470287\tvalid_1's rmse: 0.472611\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.471473\tvalid_1's rmse: 0.468425\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.470177\tvalid_1's rmse: 0.47236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.470467\tvalid_1's rmse: 0.471756\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.470923\tvalid_1's rmse: 0.470642\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.44972\tvalid_1's rmse: 0.453161\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.450981\tvalid_1's rmse: 0.447653\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.449721\tvalid_1's rmse: 0.452015\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.449767\tvalid_1's rmse: 0.452387\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.450451\tvalid_1's rmse: 0.450023\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.465216\tvalid_1's rmse: 0.467859\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2998]\ttraining's rmse: 0.466409\tvalid_1's rmse: 0.463493\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.465125\tvalid_1's rmse: 0.467904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2995]\ttraining's rmse: 0.465456\tvalid_1's rmse: 0.467116\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2999]\ttraining's rmse: 0.466\tvalid_1's rmse: 0.465143\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\ttraining's rmse: 0.441788\tvalid_1's rmse: 0.45091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\ttraining's rmse: 0.443757\tvalid_1's rmse: 0.445024\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttraining's rmse: 0.44208\tvalid_1's rmse: 0.450458\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[202]\ttraining's rmse: 0.441384\tvalid_1's rmse: 0.450153\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\ttraining's rmse: 0.442756\tvalid_1's rmse: 0.446482\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's rmse: 0.4356\tvalid_1's rmse: 0.450918\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttraining's rmse: 0.437242\tvalid_1's rmse: 0.445648\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's rmse: 0.437284\tvalid_1's rmse: 0.450803\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\ttraining's rmse: 0.436445\tvalid_1's rmse: 0.45017\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttraining's rmse: 0.436876\tvalid_1's rmse: 0.447166\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's rmse: 0.438673\tvalid_1's rmse: 0.450855\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[201]\ttraining's rmse: 0.441453\tvalid_1's rmse: 0.444997\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\ttraining's rmse: 0.439794\tvalid_1's rmse: 0.450302\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[227]\ttraining's rmse: 0.439334\tvalid_1's rmse: 0.44967\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttraining's rmse: 0.439251\tvalid_1's rmse: 0.446519\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2214]\ttraining's rmse: 0.445022\tvalid_1's rmse: 0.450579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2334]\ttraining's rmse: 0.446131\tvalid_1's rmse: 0.445239\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2367]\ttraining's rmse: 0.444911\tvalid_1's rmse: 0.450113\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2993]\ttraining's rmse: 0.444354\tvalid_1's rmse: 0.449656\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2962]\ttraining's rmse: 0.445063\tvalid_1's rmse: 0.446789\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1754]\ttraining's rmse: 0.443323\tvalid_1's rmse: 0.45034\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1350]\ttraining's rmse: 0.445509\tvalid_1's rmse: 0.445228\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1488]\ttraining's rmse: 0.443887\tvalid_1's rmse: 0.449871\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1962]\ttraining's rmse: 0.443077\tvalid_1's rmse: 0.449687\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1874]\ttraining's rmse: 0.443997\tvalid_1's rmse: 0.446613\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttraining's rmse: 0.440413\tvalid_1's rmse: 0.450544\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\ttraining's rmse: 0.440527\tvalid_1's rmse: 0.444927\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\ttraining's rmse: 0.439702\tvalid_1's rmse: 0.45003\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\ttraining's rmse: 0.439229\tvalid_1's rmse: 0.449363\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\ttraining's rmse: 0.439822\tvalid_1's rmse: 0.446325\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's rmse: 0.439649\tvalid_1's rmse: 0.450702\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's rmse: 0.440733\tvalid_1's rmse: 0.445052\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's rmse: 0.43985\tvalid_1's rmse: 0.450147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\ttraining's rmse: 0.440281\tvalid_1's rmse: 0.449808\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's rmse: 0.440023\tvalid_1's rmse: 0.446345\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttraining's rmse: 0.439572\tvalid_1's rmse: 0.450581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttraining's rmse: 0.440637\tvalid_1's rmse: 0.444813\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttraining's rmse: 0.43982\tvalid_1's rmse: 0.450342\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\ttraining's rmse: 0.440128\tvalid_1's rmse: 0.4496\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttraining's rmse: 0.43973\tvalid_1's rmse: 0.446672\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's rmse: 0.442238\tvalid_1's rmse: 0.450578\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\ttraining's rmse: 0.443462\tvalid_1's rmse: 0.4447\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[294]\ttraining's rmse: 0.44179\tvalid_1's rmse: 0.450024\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[328]\ttraining's rmse: 0.44158\tvalid_1's rmse: 0.449533\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[277]\ttraining's rmse: 0.443005\tvalid_1's rmse: 0.446519\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\ttraining's rmse: 0.436555\tvalid_1's rmse: 0.451182\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\ttraining's rmse: 0.437454\tvalid_1's rmse: 0.44523\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttraining's rmse: 0.436527\tvalid_1's rmse: 0.45049\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's rmse: 0.437397\tvalid_1's rmse: 0.449716\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\ttraining's rmse: 0.437538\tvalid_1's rmse: 0.446739\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's rmse: 0.441296\tvalid_1's rmse: 0.450261\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\ttraining's rmse: 0.443066\tvalid_1's rmse: 0.444764\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's rmse: 0.441576\tvalid_1's rmse: 0.449925\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\ttraining's rmse: 0.441587\tvalid_1's rmse: 0.449558\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[283]\ttraining's rmse: 0.441348\tvalid_1's rmse: 0.446461\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttraining's rmse: 0.439754\tvalid_1's rmse: 0.450751\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttraining's rmse: 0.441144\tvalid_1's rmse: 0.444853\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttraining's rmse: 0.440052\tvalid_1's rmse: 0.450354\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's rmse: 0.438721\tvalid_1's rmse: 0.449726\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\ttraining's rmse: 0.438727\tvalid_1's rmse: 0.446927\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[927]\ttraining's rmse: 0.442183\tvalid_1's rmse: 0.450155\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[677]\ttraining's rmse: 0.444609\tvalid_1's rmse: 0.444941\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[813]\ttraining's rmse: 0.442821\tvalid_1's rmse: 0.449743\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[824]\ttraining's rmse: 0.442853\tvalid_1's rmse: 0.449496\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1068]\ttraining's rmse: 0.442568\tvalid_1's rmse: 0.446503\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1839]\ttraining's rmse: 0.444313\tvalid_1's rmse: 0.450285\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1410]\ttraining's rmse: 0.446268\tvalid_1's rmse: 0.444939\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1628]\ttraining's rmse: 0.444645\tvalid_1's rmse: 0.449823\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1987]\ttraining's rmse: 0.444293\tvalid_1's rmse: 0.449541\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1848]\ttraining's rmse: 0.445182\tvalid_1's rmse: 0.446619\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[302]\ttraining's rmse: 0.439486\tvalid_1's rmse: 0.450388\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\ttraining's rmse: 0.441844\tvalid_1's rmse: 0.444711\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\ttraining's rmse: 0.439768\tvalid_1's rmse: 0.450093\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's rmse: 0.440802\tvalid_1's rmse: 0.449586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[330]\ttraining's rmse: 0.439712\tvalid_1's rmse: 0.446103\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1551]\ttraining's rmse: 0.444643\tvalid_1's rmse: 0.450237\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1728]\ttraining's rmse: 0.445611\tvalid_1's rmse: 0.444902\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1687]\ttraining's rmse: 0.444373\tvalid_1's rmse: 0.449877\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2064]\ttraining's rmse: 0.44403\tvalid_1's rmse: 0.449416\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1958]\ttraining's rmse: 0.444866\tvalid_1's rmse: 0.446778\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\ttraining's rmse: 0.441442\tvalid_1's rmse: 0.450429\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's rmse: 0.44251\tvalid_1's rmse: 0.444606\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[312]\ttraining's rmse: 0.440003\tvalid_1's rmse: 0.450021\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[227]\ttraining's rmse: 0.441743\tvalid_1's rmse: 0.449496\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[304]\ttraining's rmse: 0.44098\tvalid_1's rmse: 0.446414\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[229]\ttraining's rmse: 0.439387\tvalid_1's rmse: 0.450665\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[222]\ttraining's rmse: 0.440786\tvalid_1's rmse: 0.445\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[222]\ttraining's rmse: 0.439359\tvalid_1's rmse: 0.450185\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\ttraining's rmse: 0.439024\tvalid_1's rmse: 0.449716\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's rmse: 0.439521\tvalid_1's rmse: 0.446455\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[687]\ttraining's rmse: 0.442859\tvalid_1's rmse: 0.45032\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[702]\ttraining's rmse: 0.444141\tvalid_1's rmse: 0.444761\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[654]\ttraining's rmse: 0.443084\tvalid_1's rmse: 0.44988\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[894]\ttraining's rmse: 0.44212\tvalid_1's rmse: 0.449393\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[819]\ttraining's rmse: 0.443247\tvalid_1's rmse: 0.446403\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[323]\ttraining's rmse: 0.440305\tvalid_1's rmse: 0.450377\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[295]\ttraining's rmse: 0.441946\tvalid_1's rmse: 0.444669\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's rmse: 0.441463\tvalid_1's rmse: 0.449905\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[319]\ttraining's rmse: 0.440524\tvalid_1's rmse: 0.449177\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's rmse: 0.440724\tvalid_1's rmse: 0.446345\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttraining's rmse: 0.438383\tvalid_1's rmse: 0.450838\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[362]\ttraining's rmse: 0.440206\tvalid_1's rmse: 0.444927\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[389]\ttraining's rmse: 0.438531\tvalid_1's rmse: 0.450465\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[390]\ttraining's rmse: 0.43852\tvalid_1's rmse: 0.449598\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[433]\ttraining's rmse: 0.438786\tvalid_1's rmse: 0.446634\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1697]\ttraining's rmse: 0.444891\tvalid_1's rmse: 0.45038\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1835]\ttraining's rmse: 0.445977\tvalid_1's rmse: 0.445011\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1746]\ttraining's rmse: 0.444906\tvalid_1's rmse: 0.450021\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2352]\ttraining's rmse: 0.444225\tvalid_1's rmse: 0.449509\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2328]\ttraining's rmse: 0.444901\tvalid_1's rmse: 0.446823\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2108]\ttraining's rmse: 0.44435\tvalid_1's rmse: 0.450325\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1594]\ttraining's rmse: 0.44648\tvalid_1's rmse: 0.445136\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1764]\ttraining's rmse: 0.444764\tvalid_1's rmse: 0.449997\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2595]\ttraining's rmse: 0.443962\tvalid_1's rmse: 0.449511\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1876]\ttraining's rmse: 0.44554\tvalid_1's rmse: 0.446885\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2995]\ttraining's rmse: 0.447089\tvalid_1's rmse: 0.451434\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.44856\tvalid_1's rmse: 0.446057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2898]\ttraining's rmse: 0.447225\tvalid_1's rmse: 0.450896\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2998]\ttraining's rmse: 0.447308\tvalid_1's rmse: 0.450753\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2999]\ttraining's rmse: 0.447998\tvalid_1's rmse: 0.448042\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[588]\ttraining's rmse: 0.442949\tvalid_1's rmse: 0.450047\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[642]\ttraining's rmse: 0.44386\tvalid_1's rmse: 0.444838\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[560]\ttraining's rmse: 0.443148\tvalid_1's rmse: 0.449907\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[677]\ttraining's rmse: 0.442607\tvalid_1's rmse: 0.449533\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[634]\ttraining's rmse: 0.443661\tvalid_1's rmse: 0.446561\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[622]\ttraining's rmse: 0.442862\tvalid_1's rmse: 0.450231\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[653]\ttraining's rmse: 0.443974\tvalid_1's rmse: 0.444889\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[676]\ttraining's rmse: 0.442491\tvalid_1's rmse: 0.449937\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[683]\ttraining's rmse: 0.442671\tvalid_1's rmse: 0.449433\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[654]\ttraining's rmse: 0.44353\tvalid_1's rmse: 0.446548\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[426]\ttraining's rmse: 0.444272\tvalid_1's rmse: 0.450126\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[719]\ttraining's rmse: 0.443549\tvalid_1's rmse: 0.444682\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[652]\ttraining's rmse: 0.442673\tvalid_1's rmse: 0.449771\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[812]\ttraining's rmse: 0.441925\tvalid_1's rmse: 0.449324\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[685]\ttraining's rmse: 0.44338\tvalid_1's rmse: 0.446486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[574]\ttraining's rmse: 0.443033\tvalid_1's rmse: 0.450155\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[535]\ttraining's rmse: 0.444581\tvalid_1's rmse: 0.444565\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[577]\ttraining's rmse: 0.443077\tvalid_1's rmse: 0.449743\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[601]\ttraining's rmse: 0.443101\tvalid_1's rmse: 0.449406\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[675]\ttraining's rmse: 0.443421\tvalid_1's rmse: 0.446395\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[468]\ttraining's rmse: 0.443745\tvalid_1's rmse: 0.450232\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[632]\ttraining's rmse: 0.444024\tvalid_1's rmse: 0.444486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[523]\ttraining's rmse: 0.443328\tvalid_1's rmse: 0.449758\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[575]\ttraining's rmse: 0.443264\tvalid_1's rmse: 0.449495\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[730]\ttraining's rmse: 0.443046\tvalid_1's rmse: 0.446414\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's rmse: 0.442355\tvalid_1's rmse: 0.450433\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[370]\ttraining's rmse: 0.444238\tvalid_1's rmse: 0.444897\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\ttraining's rmse: 0.444241\tvalid_1's rmse: 0.449876\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[400]\ttraining's rmse: 0.442808\tvalid_1's rmse: 0.449546\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[504]\ttraining's rmse: 0.442936\tvalid_1's rmse: 0.44647\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[563]\ttraining's rmse: 0.443884\tvalid_1's rmse: 0.450186\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[674]\ttraining's rmse: 0.444706\tvalid_1's rmse: 0.444814\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[619]\ttraining's rmse: 0.443748\tvalid_1's rmse: 0.449821\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[632]\ttraining's rmse: 0.443761\tvalid_1's rmse: 0.449333\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's rmse: 0.444128\tvalid_1's rmse: 0.446571\n",
      "Best CV RMSE (LGBM): 19.39923843808385\n",
      "Best params (LGBM): {'learning_rate': 0.044178121043156375, 'num_leaves': 67, 'max_depth': 4, 'min_data_in_leaf': 27, 'feature_fraction': 0.8343568042100146, 'bagging_fraction': 0.9473869354783899, 'bagging_freq': 2, 'lambda_l1': 0.10457742075166329, 'lambda_l2': 0.0004951102145322123}\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "import optuna, lightgbm as lgb, numpy as np, pandas as pd, os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "os.environ[\"LGBM_DEVICE_TYPE\"] = \"cpu\" \n",
    "\n",
    "train = pd.read_csv(\"/kaggle/input/4datathon/prepared_train.csv\")\n",
    "test  = pd.read_csv(\"/kaggle/input/4datathon/prepared_test.csv\")\n",
    "sample = pd.read_csv(\"/kaggle/input/4datathon/sample_submission.csv\")\n",
    "\n",
    "core = [\"unique_products\",\"unique_categories\",\"event_type_ADD_CART\",\"event_type_BUY\",\n",
    "        \"event_type_REMOVE_CART\",\"event_type_VIEW\",\"duration\"]\n",
    "time = core + [\"hour\",\"day_of_week\",\"day_of_month\"]\n",
    "features = time if all(c in train.columns for c in time) else core\n",
    "\n",
    "X, y = train[features], train[\"session_value\"].astype(float)\n",
    "KFOLDS = 5\n",
    "kf = KFold(n_splits=KFOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "def objective_lgb(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.06, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 127),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 10),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 120),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.7, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.7, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 5),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 1.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 1.0, log=True),\n",
    "        \"random_state\": 42,\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "\n",
    "    y_log = np.log1p(y)\n",
    "    rmses = []\n",
    "    for tr_idx, va_idx in kf.split(X, y):\n",
    "        Xtr, Xva = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        ytr, yva = y_log.iloc[tr_idx], y_log.iloc[va_idx]\n",
    "\n",
    "        dtr = lgb.Dataset(Xtr, label=ytr)\n",
    "        dva = lgb.Dataset(Xva, label=yva, reference=dtr)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            dtr,\n",
    "            num_boost_round=3000,\n",
    "            valid_sets=[dtr, dva],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=100),\n",
    "                lgb.log_evaluation(0)\n",
    "            ],\n",
    "        )\n",
    "        p = model.predict(Xva, num_iteration=model.best_iteration)\n",
    "        rmse = np.sqrt(mean_squared_error(np.expm1(yva), np.expm1(p)))\n",
    "        rmses.append(rmse)\n",
    "    return float(np.mean(rmses))\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=0, interval_steps=1)\n",
    "study_lgb = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
    "study_lgb.optimize(objective_lgb, n_trials=40)\n",
    "\n",
    "print(\"Best CV RMSE (LGBM):\", study_lgb.best_value)\n",
    "print(\"Best params (LGBM):\", study_lgb.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T22:55:10.256578Z",
     "iopub.status.busy": "2025-08-28T22:55:10.256254Z",
     "iopub.status.idle": "2025-08-28T23:27:34.791127Z",
     "shell.execute_reply": "2025-08-28T23:27:34.790270Z",
     "shell.execute_reply.started": "2025-08-28T22:55:10.256553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['unique_products', 'unique_categories', 'event_type_ADD_CART', 'event_type_BUY', 'event_type_REMOVE_CART', 'event_type_VIEW', 'duration', 'hour', 'day_of_week', 'day_of_month']\n",
      "Best CV RMSE (CatBoost): 19.075487209144228\n",
      "Best params (CatBoost): {'learning_rate': 0.02391012381358478, 'depth': 4, 'l2_leaf_reg': 1.016026708301995, 'bagging_temperature': 1.5559082067444363, 'random_strength': 3.130981007010143, 'border_count': 97}\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "# CatBoost + Optuna Hyperparam Tuning \n",
    "\n",
    "!pip -q install optuna catboost\n",
    "\n",
    "import numpy as np, pandas as pd, optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "train = pd.read_csv(\"/kaggle/input/4datathon/prepared_train.csv\")\n",
    "test  = pd.read_csv(\"/kaggle/input/4datathon/prepared_test.csv\")\n",
    "sample = pd.read_csv(\"/kaggle/input/4datathon/sample_submission.csv\")\n",
    "\n",
    "core = [\"unique_products\",\"unique_categories\",\n",
    "        \"event_type_ADD_CART\",\"event_type_BUY\",\n",
    "        \"event_type_REMOVE_CART\",\"event_type_VIEW\",\n",
    "        \"duration\"]\n",
    "time = core + [\"hour\",\"day_of_week\",\"day_of_month\"]\n",
    "features = time if all(c in train.columns for c in time) else core\n",
    "print(\"Using features:\", features)\n",
    "\n",
    "X, y = train[features], train[\"session_value\"].astype(float)\n",
    "X_test = test[features]\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "KFOLDS = 5\n",
    "kf = KFold(n_splits=KFOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "def objective_cb(trial):\n",
    "    params = {\n",
    "        \"loss_function\": \"RMSE\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.08, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 20.0, log=True),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 5.0),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 0.5, 5.0, log=True),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": False,\n",
    "        \"task_type\": \"GPU\" if False else \"CPU\",\n",
    "        # Early stopping\n",
    "        \"od_type\": \"Iter\",\n",
    "        \"od_wait\": 200\n",
    "    }\n",
    "    rmses = []\n",
    "    for tr_idx, va_idx in kf.split(X, y):\n",
    "        Xtr, Xva = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        ytr, yva = y_log.iloc[tr_idx], y_log.iloc[va_idx]\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            **params,\n",
    "            iterations=5000\n",
    "        )\n",
    "        model.fit(Xtr, ytr, eval_set=(Xva, yva), verbose=False)\n",
    "        p = model.predict(Xva)\n",
    "        rmse = np.sqrt(mean_squared_error(np.expm1(yva), np.expm1(p)))\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return float(np.mean(rmses))\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_cb = optuna.create_study(direction=\"minimize\",\n",
    "                               pruner=optuna.pruners.MedianPruner(n_startup_trials=5, interval_steps=1))\n",
    "study_cb.optimize(objective_cb, n_trials=40)\n",
    "\n",
    "print(\"Best CV RMSE (CatBoost):\", study_cb.best_value)\n",
    "print(\"Best params (CatBoost):\", study_cb.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T23:30:16.315447Z",
     "iopub.status.busy": "2025-08-28T23:30:16.315118Z",
     "iopub.status.idle": "2025-08-28T23:31:35.341052Z",
     "shell.execute_reply": "2025-08-28T23:31:35.340277Z",
     "shell.execute_reply.started": "2025-08-28T23:30:16.315417Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[574]\ttraining's rmse: 0.443033\tvalid_1's rmse: 0.450155\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[535]\ttraining's rmse: 0.444581\tvalid_1's rmse: 0.444565\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[577]\ttraining's rmse: 0.443077\tvalid_1's rmse: 0.449743\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[729]\ttraining's rmse: 0.442346\tvalid_1's rmse: 0.449385\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[675]\ttraining's rmse: 0.443421\tvalid_1's rmse: 0.446395\n",
      "OOF RMSEs: {'XGB': 19.163895601382755, 'LGBM': 19.555256299610907, 'CatBoost': 19.20897754710921}\n",
      "Best OOF RMSE (blend): 19.08722805556598\n",
      "Best weights: {'w_xgb': 0.4920647886263625, 'w_lgb': 0.00013259547077216311, 'w_cb': 0.38037643147630024}\n",
      "Saved: submission_blended.csv\n",
      "Saved: individual submissions (xgb/lgb/cb)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#4\n",
    "\n",
    "import numpy as np, pandas as pd, optuna, xgboost as xgb, lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train = pd.read_csv(\"/kaggle/input/4datathon/prepared_train.csv\")\n",
    "test  = pd.read_csv(\"/kaggle/input/4datathon/prepared_test.csv\")\n",
    "sample = pd.read_csv(\"/kaggle/input/4datathon/sample_submission.csv\")\n",
    "\n",
    "core = [\"unique_products\",\"unique_categories\",\n",
    "        \"event_type_ADD_CART\",\"event_type_BUY\",\n",
    "        \"event_type_REMOVE_CART\",\"event_type_VIEW\",\n",
    "        \"duration\"]\n",
    "time = core + [\"hour\",\"day_of_week\",\"day_of_month\"]\n",
    "features = time if all(c in train.columns for c in time) else core\n",
    "X, y = train[features], train[\"session_value\"].astype(float)\n",
    "X_test = test[features]\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "KFOLDS = 5\n",
    "kf = KFold(n_splits=KFOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "#XGBoost best params\n",
    "xgb_params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"eta\": 0.055091126943701545,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_child_weight\": 1.737491912946531,\n",
    "    \"subsample\": 0.7175975747321702,\n",
    "    \"colsample_bytree\": 0.819515614621276,\n",
    "    \"reg_alpha\": 2.2870536596663814e-07,\n",
    "    \"reg_lambda\": 4.347571964357222,\n",
    "    \"gamma\": 0.25383082245869804,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "def fit_xgb(Xtr, ytr, Xva, yva, params, num_boost_round=10000, early_stopping_rounds=300):\n",
    "    dtr = xgb.DMatrix(Xtr, label=ytr)\n",
    "    dva = xgb.DMatrix(Xva, label=yva)\n",
    "    booster = xgb.train(params, dtr, num_boost_round=num_boost_round,\n",
    "                        evals=[(dtr,\"train\"),(dva,\"valid\")],\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        verbose_eval=False)\n",
    "    return booster\n",
    "\n",
    "def xgb_predict(booster, X_):\n",
    "    d_ = xgb.DMatrix(X_)\n",
    "    ntree_limit = getattr(booster, \"best_ntree_limit\", 0)\n",
    "    return booster.predict(d_, ntree_limit=ntree_limit) if ntree_limit else booster.predict(d_)\n",
    "\n",
    "#LightGBM best params\n",
    "lgb_params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.044178121043156375,\n",
    "    \"num_leaves\": 67,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_data_in_leaf\": 27,\n",
    "    \"feature_fraction\": 0.8343568042100146,\n",
    "    \"bagging_fraction\": 0.9473869354783899,\n",
    "    \"bagging_freq\": 2,\n",
    "    \"lambda_l1\": 0.10457742075166329,\n",
    "    \"lambda_l2\": 0.0004951102145322123,\n",
    "    \"random_state\": 42,\n",
    "    \"verbosity\": -1\n",
    "}\n",
    "\n",
    "#CatBoost best params\n",
    "cb_best = {\n",
    "    \"learning_rate\": 0.02391012381358478,\n",
    "    \"depth\": 4,\n",
    "    \"l2_leaf_reg\": 1.016026708301995,\n",
    "    \"bagging_temperature\": 1.5559082067444363,\n",
    "    \"random_strength\": 3.130981007010143,\n",
    "    \"border_count\": 97\n",
    "}\n",
    "\n",
    "#Fold OOF + Test\n",
    "oof_xgb = np.zeros(len(X)); test_xgb = np.zeros(len(X_test))\n",
    "oof_lgb = np.zeros(len(X)); test_lgb = np.zeros(len(X_test))\n",
    "oof_cb  = np.zeros(len(X)); test_cb  = np.zeros(len(X_test))\n",
    "\n",
    "for tr_idx, va_idx in kf.split(X, y):\n",
    "    Xtr, Xva = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    ytr, yva = y_log.iloc[tr_idx], y_log.iloc[va_idx]\n",
    "\n",
    "    # XGB\n",
    "    booster = fit_xgb(Xtr, ytr, Xva, yva, xgb_params)\n",
    "    p_va = xgb_predict(booster, Xva)\n",
    "    p_te = xgb_predict(booster, X_test)\n",
    "    oof_xgb[va_idx] = np.expm1(p_va); test_xgb += np.expm1(p_te)/KFOLDS\n",
    "\n",
    "    # LGBM\n",
    "    dtr = lgb.Dataset(Xtr, label=ytr); dva = lgb.Dataset(Xva, label=yva, reference=dtr)\n",
    "    mdl_lgb = lgb.train(lgb_params, dtr, num_boost_round=10000,\n",
    "                        valid_sets=[dtr, dva],\n",
    "                        callbacks=[lgb.early_stopping(300), lgb.log_evaluation(0)])\n",
    "    p_va = mdl_lgb.predict(Xva, num_iteration=mdl_lgb.best_iteration)\n",
    "    p_te = mdl_lgb.predict(X_test, num_iteration=mdl_lgb.best_iteration)\n",
    "    oof_lgb[va_idx] = np.expm1(p_va); test_lgb += np.expm1(p_te)/KFOLDS\n",
    "\n",
    "    # CatBoost\n",
    "    mdl_cb = CatBoostRegressor(\n",
    "        loss_function=\"RMSE\", random_seed=42, verbose=False,\n",
    "        iterations=10000, od_type=\"Iter\", od_wait=300, use_best_model=True,\n",
    "        learning_rate=cb_best[\"learning_rate\"],\n",
    "        depth=cb_best[\"depth\"],\n",
    "        l2_leaf_reg=cb_best[\"l2_leaf_reg\"],\n",
    "        bagging_temperature=cb_best[\"bagging_temperature\"],\n",
    "        random_strength=cb_best[\"random_strength\"],\n",
    "        border_count=cb_best[\"border_count\"],\n",
    "        task_type=\"CPU\"\n",
    "    )\n",
    "    mdl_cb.fit(Xtr, ytr, eval_set=(Xva, yva), verbose=False)\n",
    "    p_va = mdl_cb.predict(Xva); p_te = mdl_cb.predict(X_test)\n",
    "    oof_cb[va_idx] = np.expm1(p_va); test_cb += np.expm1(p_te)/KFOLDS\n",
    "\n",
    "# OOF RMSEler\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y, oof_xgb))\n",
    "rmse_lgb = np.sqrt(mean_squared_error(y, oof_lgb))\n",
    "rmse_cb  = np.sqrt(mean_squared_error(y, oof_cb))\n",
    "print(\"OOF RMSEs:\", {\"XGB\":rmse_xgb, \"LGBM\":rmse_lgb, \"CatBoost\":rmse_cb})\n",
    "\n",
    "def blend_objective(trial):\n",
    "    w1 = trial.suggest_float(\"w_xgb\", 0.0, 1.0)\n",
    "    w2 = trial.suggest_float(\"w_lgb\", 0.0, 1.0)\n",
    "    w3 = trial.suggest_float(\"w_cb\",  0.0, 1.0)\n",
    "    s  = w1 + w2 + w3 + 1e-12\n",
    "    pred = (w1*oof_xgb + w2*oof_lgb + w3*oof_cb)/s\n",
    "    return float(np.sqrt(mean_squared_error(y, pred)))\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_blend = optuna.create_study(direction=\"minimize\")\n",
    "study_blend.optimize(blend_objective, n_trials=200)\n",
    "print(\"Best OOF RMSE (blend):\", study_blend.best_value)\n",
    "print(\"Best weights:\", study_blend.best_params)\n",
    "\n",
    "# Final blended submission \n",
    "w = study_blend.best_params\n",
    "ws = w[\"w_xgb\"] + w[\"w_lgb\"] + w[\"w_cb\"] + 1e-12\n",
    "test_blend = (w[\"w_xgb\"]*test_xgb + w[\"w_lgb\"]*test_lgb + w[\"w_cb\"]*test_cb)/ws\n",
    "\n",
    "sub = sample.copy()\n",
    "sub[\"session_value\"] = test_blend\n",
    "sub.to_csv(\"submission_blended.csv\", index=False)\n",
    "print(\"Saved: submission_blended.csv\")\n",
    "\n",
    "pd.DataFrame({\"session_value\": test_xgb}, index=sample.index).to_csv(\"submission_xgb_only.csv\", index=False)\n",
    "pd.DataFrame({\"session_value\": test_lgb}, index=sample.index).to_csv(\"submission_lgb_only.csv\", index=False)\n",
    "pd.DataFrame({\"session_value\": test_cb},  index=sample.index).to_csv(\"submission_cb_only.csv\",  index=False)\n",
    "print(\"Saved: individual submissions (xgb/lgb/cb)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8149005,
     "sourceId": 12899867,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
